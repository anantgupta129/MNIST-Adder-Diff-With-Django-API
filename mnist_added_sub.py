# -*- coding: utf-8 -*-
"""mnist_added_sub.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-7fAOR3zvwznlngEjKPqeiWZXv2asm9e

# Import Libraries
"""

import torch
import torch.nn.functional as F
import torch.optim as optim
import torchvision
from torch.utils.data import DataLoader, Dataset
from torchvision import datasets, transforms
from tqdm import tqdm

from mnist.custom_mnist import Net

"""# Download the data"""

# For training set 
# Making the tensor and normalizing the data
train_set = torchvision.datasets.MNIST(
    root='data/',  # creating directory and giving the path
    train=True,     # True for training set
    download=True,  # True if data is not available in local storage
    transform=transforms.Compose([
        transforms.ToTensor(), # convert image to tensor
        transforms.Normalize((0.1307,), (0.3081,)) # Normalize image with mean and standard deviation
    ])
)

# For testing set
# Making the tensor and normalizing the data
test_set = torchvision.datasets.MNIST(
    root='data/',    #  giving the directory path
    train=False,      # False for testing set
    transform=transforms.Compose([
        transforms.ToTensor(),  # convert image to tensor
        transforms.Normalize((0.1307,), (0.3081,))   # Normalize image with mean and standard deviation
    ])
)

"""# DataSet Class"""

class MNISTNum(Dataset):
  def __init__(self, data):
    self.data = data
    self.rand_nums = torch.randint(0, 10, ((len(data)),1), dtype=torch.float)

  def __getitem__(self, i):
    image, label = self.data[i]
    num = self.rand_nums[i]

    sum = label + num
    diff = abs(label - num)
    
    return image, num, label, sum, diff

  def __len__(self):
    return len(self.data)

"""# Train Test Loaders"""

torch.manual_seed(1)
batch_size = 256
use_cuda = torch.cuda.is_available() # GPU enabled
kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}

train_loader = DataLoader(
    MNISTNum(train_set),
    batch_size=batch_size,
    shuffle=True,
    **kwargs
)

test_loader = DataLoader(
    MNISTNum(test_set),
    batch_size=batch_size,
    shuffle=True,
    **kwargs
)


""" Loading network"""

model = Net()
print(model)

"""# Training"""

device = torch.device("cuda" if use_cuda else "cpu")

def train(model, device, train_loader, optimizer, epoch):
    model.train()
    pbar = tqdm(train_loader)
    for batch_idx, (images, nums, labels, sums, diffs) in enumerate(pbar):
        images, nums, labels, sums, diffs = images.to(device), nums.to(device), labels.to(device), sums.to(device), diffs.to(device)
        
        optimizer.zero_grad()
        pred_lab, pred_sum, pred_diff = model(images, nums)

        loss1 = F.nll_loss(pred_lab, labels)
        loss2 = torch.sqrt(F.mse_loss(pred_sum, sums))
        loss3 = torch.sqrt(F.mse_loss(pred_diff, diffs))
        loss = loss1 + loss2 + loss3

        loss.backward()
        optimizer.step()
        pbar.set_description(desc= f'batch_id={batch_idx} loss={loss.item():.5f} RMSE={loss2.item()+loss3.item():.5f}')


def test(model, device, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    rmse_loss = 0
    with torch.no_grad():
        for images, nums, labels, sums, diffs in test_loader:
            images, nums, labels, sums, diffs = images.to(device), nums.to(device), labels.to(device), sums.to(device), diffs.to(device)
            pred_lab, pred_sum, pred_diff = model(images, nums)

            loss1 = F.nll_loss(pred_lab, labels, reduction='sum')
            loss2 = torch.sqrt(F.mse_loss(pred_sum, sums, reduction='sum'))
            loss3 = torch.sqrt(F.mse_loss(pred_diff, diffs, reduction='sum'))
            loss = loss1 + loss2 + loss3
          
            test_loss += loss.item()  # sum up batch loss
            rmse_loss += loss2.item() + loss3.item()
            pred = pred_lab.argmax(dim=1, keepdim=True)  # get the index of the max log-probability
            correct += pred.eq(labels.view_as(pred)).sum().item()

    test_loss /= len(test_loader.dataset)
    rmse_loss /= len(test_loader.dataset)

    print('Test set: Average loss: {:.4f}, RMSE: {:.4f} Accuracy: {}/{} ({:.2f}%)\n'.format(
        test_loss, rmse_loss, correct, len(test_loader.dataset),
        100. * correct / len(test_loader.dataset)))

model = Net().to(device)
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)
num_epoch = 25

for epoch in range(1, num_epoch+1):
  print('EPOCH: ',epoch)
  train(model, device, train_loader, optimizer, epoch)
  test(model, device, test_loader)

torch.save(model.state_dict(), 'weights/model.pt')

